{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Questions 1 to 5 refer to the following scenario:\n",
    "\n",
    "Suppose a binary classifier produced the following confusion matrix.\n",
    "\n",
    "|      &nbsp;     | Predicted Positive | Predicted Negative |\n",
    "|-----------------|--------------------|--------------------|\n",
    "| Actual Positive | 5600               | 40                 |\n",
    "| Actual Negative | 1900               | 2460               |\n",
    "\n",
    "What is the **recall** of this classifier? Round your answer to 2 decimal places.\n",
    "\n",
    "What is the **precision** of this classifier? Round your answer to 2 decimal places.\n",
    "\n",
    "Recall = # true positive / (# true positive + # false negatives)\n",
    "\n",
    "Precision = # true positive / (# true positive + # false positive)\n",
    "\n",
    "Accuracy = TP + TN / (TP + TN + FP + FN)\n",
    "\n",
    "    * 5600 / (5600 + 40) = 0.993\n",
    "    * 5600 / (5600 + 1900) = 0.746\n",
    "    * 5600 + 2460 / (5600 + 40 + 1900 + 2460) = 8060 / (10000) = 0.806\n",
    "    \n",
    "2. Refer to the scenario presented in Question 1 to answer the following:\n",
    "\n",
    "(True/False) This classifier is better than random guessing.\n",
    "\n",
    "    * True\n",
    "    \n",
    "3. Refer to the scenario presented in Question 1 to answer the following:\n",
    "\n",
    "(True/False) This classifier is better than the majority class classifier.\n",
    "\n",
    "    * True\n",
    "    \n",
    "4. Refer to the scenario presented in Question 1 to answer the following:\n",
    "\n",
    "Which of the following points in the precision-recall space corresponds to this classifier?\n",
    "\n",
    "    * 3\n",
    "    \n",
    "5. Refer to the scenario presented in Question 1 to answer the following:\n",
    "\n",
    "Which of the following best describes this classifier?\n",
    "\n",
    "    * It is optimistic\n",
    "    \n",
    "6. Suppose we are fitting a logistic regression model on a dataset where the vast majority of the data points are labeled as positive. To compensate for overfitting to the dominant class, we should\n",
    "    * Require higher confidence level for positive predictions\n",
    "    \n",
    "7. It is often the case that false positives and false negatives incur different costs. In situations where false negatives cost much more than false positives, we should\n",
    "    * Require lower confidence level for positive predictions\n",
    "    \n",
    "8. We are interested in reducing the number of false negatives. Which of the following metrics should we primarily look at?\n",
    "    * Recall\n",
    "    \n",
    "9. Suppose we set the threshold for positive predictions at 0.9. What is the lowest score that is classified as positive? Round your answer to 2 decimal places.\n",
    "    * 2.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
