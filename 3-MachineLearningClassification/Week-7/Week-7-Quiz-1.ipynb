{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (True/False) Stochastic gradient ascent often requires fewer passes over the dataset than batch gradient ascent to achieve a similar log likelihood.\n",
    "    * True\n",
    "\n",
    "2. (True/False) Choosing a large batch size results in less noisy gradients\n",
    "    * True\n",
    "\n",
    "3. (True/False) The set of coefficients obtained at the last iteration represents the best coefficients found so far.\n",
    "    * False\n",
    "\n",
    "4. Suppose you obtained the plot of log likelihood below after running stochastic gradient ascent.\n",
    "\n",
    "    Which of the following actions would help the most to improve the rate of convergence?\n",
    "    * Decrease step size\n",
    "\n",
    "5. Suppose you obtained the plot of log likelihood below after running stochastic gradient ascent.\n",
    "\n",
    "    Which of the following actions would help to improve the rate of convergence?\n",
    "    * Increase step size\n",
    "    \n",
    "6. Suppose it takes about 1 milliseconds to compute a gradient for a single example. You run an online advertising company and would like to do online learning via mini-batch stochastic gradient ascent. If you aim to update the coefficients once every 5 minutes, how many examples can you cover in each update? Overhead and other operations take up 2 minutes, so you only have 3 minutes for the coefficient update.\n",
    "    * 180000 milliseconds\n",
    "\n",
    "7. In search for an optimal step size, you experiment with multiple step sizes and obtain the following convergence plot.\n",
    "\n",
    "    Which line corresponds to step sizes that are smaller than the best? Select all that apply.\n",
    "    * 1\n",
    "    \n",
    "8. Suppose you run stochastic gradient ascent with two different batch sizes. Which of the two lines below corresponds to the smaller batch size (assuming both use the same step size)?\n",
    "    * 1\n",
    "\n",
    "9. Which of the following is NOT a benefit of stochastic gradient ascent over batch gradient ascent? Choose all that apply.\n",
    "    * [True] Each coefficient step is very fast.\n",
    "    * [False] Log likelihood of data improves monotonically.\n",
    "    * [True] Stochastic gradient ascent can be used for online learning.\n",
    "    * [True] Stochastic gradient ascent can achieve higher likelihood than batch gradient ascent for the same amount of running time.\n",
    "    * [False] Stochastic gradient ascent is highly robust with respect to parameter choices.\n",
    "\n",
    "10. Suppose we run the stochastic gradient ascent algorithm described in the lecture with batch size of 100. To make 10 passes over a dataset consisting of 15400 examples, how many iterations does it need to run?\n",
    "    * 1540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
