{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the following is NOT an ensemble method?\n",
    "    * Single decision trees\n",
    "\n",
    "2. Each binary classifier in an ensemble makes predictions on an input xxx as listed in the table below. Based on the ensemble coefficients also listed in the table, what is the final ensemble model's prediction for $x$?\n",
    "\n",
    "|    &nbsp;    | Classifier coefficient $w_t$ | Prediction for $x$ |\n",
    "|--------------|------------------------------|--------------------|\n",
    "| Classifier 1 | 0.61                         | +1                 |\n",
    "| Classifier 2 | 0.53                         | -1                 |\n",
    "| Classifier 3 | 0.88                         | -1                 |\n",
    "| Classifier 4 | 0.34                         | +1                 |\n",
    "\n",
    "    * -1\n",
    "\n",
    "3. (True/False) Boosted trees tend to be more robust to overfitting than decision trees.\n",
    "    * True\n",
    "    \n",
    "3.1 (True/False) Boosted decision stumps is a linear classifier.\n",
    "    * False\n",
    "\n",
    "4. (True/False) AdaBoost focuses on data points it incorrectly predicted by increasing those weights in the data set.\n",
    "    * True\n",
    "    \n",
    "4.1 (True/False) For AdaBoost, test error is an appropriate criterion for choosing the optimal number of iterations.\n",
    "    * False\n",
    "\n",
    "5. Let $w_t$ be the coefficient for a weak learner $f_t$. Which of the following conditions must be true so that $w_t > 0$ ?\n",
    "    * weighted_error$(f_t)<.5$\n",
    "    \n",
    "5.1 In an iteration in AdaBoost, recall that learning the coefficient $w_t$ for learned weak learner $f_t$ is calculated by\n",
    "\n",
    "If the weighted error of $f_t$ is equal to .25, what is the value of $w_t$? Round your answer to 2 decimal places.\n",
    "    * 0.55\n",
    "\n",
    "6. Which of the following classifiers is most accurate as computed on a weighted dataset? A classifier with:\n",
    "    * weighted error = 0.1\n",
    "\n",
    "7. Imagine we are training a decision stump in an iteration of AdaBoost, and we are at a node. Each data point is (x1, x2, y), where x1,x2 are features, and y is the label. Also included are the weights of the data. The data at this node is:\n",
    "\n",
    "| Weight | x1 | x2 | y  |\n",
    "|--------|----|----|----|\n",
    "| 0.3    | 0  | 1  | +1 |\n",
    "| 0.35   | 1  | 0  | -1 |\n",
    "| 0.1    | 0  | 1  | +1 |\n",
    "| 0.25   | 1  | 1  | +1 |\n",
    "\n",
    "Suppose we split on feature x2. Calculate the weighted error of this split. Round your answer to 2 decimal places.\n",
    "    * 0.35\n",
    "\n",
    "8. After each iteration of AdaBoost, the weights on the data points are typically normalized to sum to 1. This is used because\n",
    "    * of issues with numerical instability (underflow/overflow)\n",
    "\n",
    "9. Consider the following 2D dataset with binary labels.\n",
    "\n",
    "We train a series of weak binary classifiers using AdaBoost. In one iteration, the weak binary classifier produces the decision boundary as follows:\n",
    "\n",
    "    * 2\n",
    "    * 3\n",
    "\n",
    "10. Suppose we are running AdaBoost using decision tree stumps. At a particular iteration, the data points have weights according the figure. (Large points indicate heavy weights.)\n",
    "\n",
    "Which of the following decision tree stumps is most likely to be fit in the next iteration?\n",
    "\n",
    "    * a\n",
    "\n",
    "11. (True/False) AdaBoost can boost any kind of classifier, not just a decision tree stump.\n",
    "    * True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
