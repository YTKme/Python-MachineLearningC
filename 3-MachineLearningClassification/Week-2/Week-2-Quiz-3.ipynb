{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consider four classifiers, whose classification performance is given by the following table:\n",
    "\n",
    "| &nbsp;       | Classification error on training set | Classification error on validation set |\n",
    "|--------------|--------------------------------------|----------------------------------------|\n",
    "| Classifier 1 | 0.2                                  | 0.6                                    |\n",
    "| Classifier 2 | 0.8                                  | 0.6                                    |\n",
    "| Classifier 3 | 0.2                                  | 0.2                                    |\n",
    "| Classifier 4 | 0.5                                  | 0.4                                    |\n",
    "\n",
    "Which of the four classifiers is most likely overfit?\n",
    "    * Classifier 1\n",
    "\n",
    "2. Suppose a classifier classifies 23100 examples correctly and 1900 examples incorrectly. Compute accuracy by hand. Round your answer to 3 decimal places.\n",
    "    * 0.924 (accuracy)\n",
    "    * 0.076 (error)\n",
    "\n",
    "3. (True/False) Accuracy and error measured on the same dataset always sum to 1.\n",
    "    * True\n",
    "\n",
    "4.  Which of the following is NOT a correct description of complex models?\n",
    "    * Complex models tend to generalize better than simple models.\n",
    "\n",
    "5. Which of the following is a symptom of overfitting in the context of logistic regression? Select all that apply.\n",
    "    * Large estimated coefficients\n",
    "    * Complex decision boundary\n",
    "    * Overconfident predictions of class probabilities\n",
    "\n",
    "6. Suppose we perform L2 regularized logistic regression to fit a sentiment classifier. Which of the following plots does NOT describe a possible coefficient path? Choose all that apply.\n",
    "\n",
    "**Note.** Assume that the algorithm runs for a wide range of L2 penalty values and each coefficient plot is zoomed out enough to capture all long-term trends.\n",
    "    * 3 X\n",
    "    * 4 X\n",
    "\n",
    "7. Suppose we perform L1 regularized logistic regression to fit a sentiment classifier. Which of the following plots does NOT describe a possible coefficient path? Choose all that apply.\n",
    "\n",
    "**Note.** Assume that the algorithm runs for a wide range of L1 penalty values and each coefficient plot is zoomed out enough to capture all long-term trends.\n",
    "    * 1\n",
    "    * 4\n",
    "\n",
    "8. In the context of L2 regularized logistic regression, which of the following occurs as we increase the L2 penalty $\\lambda$ Choose all that apply.\n",
    "    * [X] The L2 norm of the set of coefficients gets smaller\n",
    "    * Region of uncertainty becomes narrower, i.e., the classifier makes predictions with higher confidence.\n",
    "    * [X] Decision boundary becomes less complex\n",
    "    * Training error decreases\n",
    "    * [X] The classifier has lower variance\n",
    "    * Some features are excluded from the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
