{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. (True/False) When learning decision trees, smaller depth USUALLY translates to lower training error.\n",
    "    * False\n",
    "\n",
    "2. (True/False) If no two data points have the same input values, we can always learn a decision tree that achieves 0 training error.\n",
    "    * True\n",
    "\n",
    "3. (True/False) If decision tree T1 has lower training error than decision tree T2, then T1 will always have better test error than T2.\n",
    "    * False\n",
    "\n",
    "4. Which of the following is true for decision trees?\n",
    "    * Model complexity increases with depth.\n",
    "\n",
    "5. Pruning and early stopping in decision trees is used to\n",
    "    * combat overfitting\n",
    "\n",
    "6. Which of the following is NOT an early stopping method?\n",
    "    * Stop when every possible split results in the same amount of error reduction\n",
    "\n",
    "7. Consider decision tree T1 learned with minimum node size parameter = 1000. Now consider decision tree T2 trained on the same dataset and parameters, except that the minimum node size parameter is now 100. Which of the following is always true?\n",
    "    * The depth of T2 >= the depth of T1\n",
    "    * The number of nodes in T2 >= the number of nodes in T1\n",
    "    * The training error of T2 <= the training error of T1\n",
    "\n",
    "8. Questions 8 to 11 refer to the following common scenario:\n",
    "\n",
    "Imagine we are training a decision tree, and we are at a node. Each data point is (x1, x2, y), where x1,x2 are features, and y is the label. The data at this node is:\n",
    "\n",
    "| x1 | x2 |  y |\n",
    "|----|----|----|\n",
    "| 0  | 1  | +1 |\n",
    "| 1  | 0  | +1 |\n",
    "| 0  | 1  | +1 |\n",
    "| 1  | 1  | -1 |\n",
    "\n",
    "What is the classification error at this node (assuming a majority class classifier)?\n",
    "\n",
    "    * 0.25\n",
    "\n",
    "9. Refer to the scenario presented in Question 8.\n",
    "\n",
    "If we split on x1, what is the classification error?\n",
    "\n",
    "    * 0.25\n",
    "\n",
    "10. Refer to the scenario presented in Question 8.\n",
    "\n",
    "If we split on x2, what is the classification error?\n",
    "\n",
    "    * 0.25\n",
    "\n",
    "11. Refer to the scenario presented in Question 8.\n",
    "\n",
    "If our parameter for minimum gain in error reduction is 0.1, do we split or stop early?\n",
    "\n",
    "    * Stop early"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
